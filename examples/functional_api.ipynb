{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Æ’() Functional API\n",
    "\n",
    "In this tutorial, we'll see an example of using Composer's algorithms in a standalone fashion with no changes to the surrounding code and no requirement to use the Composer trainer.\n",
    "\n",
    "### Recommended Background\n",
    "\n",
    "This tutorial assumes that you have a working familiarity with PyTorch training loops and a general familiarity with Composer algorithms. To brush up on the latter, check out our [docs][algorithm_docs].\n",
    "\n",
    "### Tutorial Goals and Concepts Covered\n",
    "\n",
    "The key new concept introduced here is the [functional API][api_docs] for algorithms. The goal of this tutorial is to provide some familiarity with its usage.\n",
    "\n",
    "We'll be training a simple model on CIFAR-10, similar to the [PyTorch classifier tutorial][pytorch_tutorial]. Because we'll be using a toy model trained for only a few epochs, we won't get the same speed or accuracy gains we might expect from a more realistic problem. However, this tutorial should still serve as a useful illustration of how to use various algorithms. For examples of more realistic results, see the MosaicML [Explorer][explorer].\n",
    "\n",
    "[algorithm_docs]: https://docs.mosaicml.com/en/stable/trainer/algorithms.html\n",
    "[api_docs]: https://docs.mosaicml.com/en/stable/functional_api.html\n",
    "[pytorch_tutorial]: https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html\n",
    "[explorer]: https://app.mosaicml.com/explorer/imagenet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Composer\n",
    "\n",
    "If you don't already have composer installed, install it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install mosaicml\n",
    "# To install from source instead of the last release, comment the command above and uncomment the following one.\n",
    "# %pip install git+https://github.com/mosaicml/composer.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the Model, Dataloader, and Training Loop\n",
    "\n",
    "First, we need to define our original model, dataloader, and training loop. Let's start with the dataloader:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.utils.data\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "datadir = './data'\n",
    "batch_size = 1024\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    ]\n",
    ")\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root=datadir, train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root=datadir, train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, we compose two transforms: one which converts the images to tensors and another that normalizes them. We apply these transformations to both the train and test sets. \n",
    "\n",
    "Now, let's define our model. We're going to use a toy convolutional neural network so that the training finishes quickly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=(3, 3), stride=2)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=(3, 3))\n",
    "        self.norm = nn.BatchNorm2d(32)\n",
    "        self.pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc1 = nn.Linear(32, 128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(self.norm(x))\n",
    "        x = torch.flatten(self.pool(x), 1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's write a simple training loop that prints the accuracy on the test set at the end of each epoch. We'll just run a few epochs for brevity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "num_epochs = 5\n",
    "\n",
    "def train_and_eval(model, train_loader, test_loader):\n",
    "    # Set up the model and optimizer\n",
    "    torch.manual_seed(42)\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    model = model.to(device)\n",
    "    opt = torch.optim.Adam(model.parameters())\n",
    "    # Run one or more epochs \n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"---- Beginning epoch {epoch} ----\")\n",
    "        model.train()\n",
    "        progress_bar = tqdm(train_loader)\n",
    "        # Train on an epoch of minibatches\n",
    "        for X, y in progress_bar:\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            y_hat = model(X)\n",
    "            loss = F.cross_entropy(y_hat, y)\n",
    "            progress_bar.set_postfix_str(f\"train loss: {loss.item():.4f}\")\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            opt.zero_grad()\n",
    "        # Evaluate the model at the end of the epoch\n",
    "        model.eval()\n",
    "        num_right = 0\n",
    "        eval_size = 0\n",
    "        for X, y in test_loader:\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            y_hat = model(X)\n",
    "            num_right += (y_hat.argmax(dim=1) == y).sum().item()\n",
    "            eval_size += len(y)\n",
    "        acc_percent = 100 * num_right / eval_size\n",
    "        print(f\"Epoch {epoch} validation accuracy: {acc_percent:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great. Now, let's instantiate this baseline model and see how it fares on our dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net()\n",
    "train_and_eval(model, trainloader, testloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have this baseline, let's add algorithms to improve our data pipeline and model. We'll start by adding some data augmentation, accessed via `cf.colout_batch`. (We can ignore the details on how `ColOut` works for the sake of this tutorial; you can check out the [docs][colout] if you'd like to learn more.)\n",
    "\n",
    "[colout]: https://docs.mosaicml.com/en/stable/method_cards/colout.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import composer.functional as cf # <-- Imports Composer's functional API\n",
    "\n",
    "# create dataloaders for the train and test sets\n",
    "shared_transforms = [\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "]\n",
    "\n",
    "# Add ColOut to the transforms used during training\n",
    "train_transforms = shared_transforms[:] + [cf.colout_batch]\n",
    "\n",
    "test_transform = transforms.Compose(shared_transforms)\n",
    "train_transform = transforms.Compose(train_transforms)\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root=datadir, train=True,\n",
    "                                        download=True, transform=train_transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                        shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root=datadir, train=False,\n",
    "                                        download=True, transform=test_transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                          shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how our model does with just these changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net()\n",
    "# only use one data augmentation since our small model runs quickly\n",
    "# and allows the dataloader little time to do anything fancy\n",
    "train_and_eval(model, trainloader, testloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we might expect, adding data augmentation doesn't help us when we aren't training long enough to start overfitting.\n",
    "\n",
    "Let's try using some algorithms that modify the model. We're going to keep things simple and just add a [Squeeze-and-Excitation][squeezeexcite] module after the larger of the two `Conv2d` operations in our model. (Again, we can ignore what `SqueezeExcite` actually does, but feel free to check the docs to learn more.)\n",
    "\n",
    "[squeezeexcite]: https://docs.mosaicml.com/en/stable/method_cards/squeeze_excite.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# squeeze-excite can add a lot of overhead for small\n",
    "# conv2d operations, so only add it after convs with a\n",
    "# minimum number of channels\n",
    "cf.apply_squeeze_excite(model, latent_channels=64, min_channels=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's see how our model does with the above algorithm applied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_and_eval(model, trainloader, testloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding squeeze-excite gives us another few percentage points of accuracy and does so with little decrease in the number of iterations per second. Great!\n",
    "\n",
    "Of course, this is a toy model and dataset, but it serves to illustrate how to use Composer's algorithms inside your own training loops, with minimal changes to your code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## What next?\n",
    "\n",
    "You've now seen some examples of how to use our speed-up algorithms outside the Composer Trainer.\n",
    "\n",
    "If you want to keep learning more, dig deeper into our functional API [documentation][docs], which includes a full list of available algorithm functions!\n",
    "\n",
    "In addition, please continue to explore our tutorials! Here's a couple suggestions:\n",
    "\n",
    "* Keep it custom with our [custom speedups][custom_speedups_tutorial] tutorial.\n",
    "\n",
    "* A [transition guide][ptl_tutorial] for switching from PyTorch Lightning to Composer.\n",
    "\n",
    "[docs]: https://docs.mosaicml.com/en/stable/functional_api.html\n",
    "[custom_speedups_tutorial]: https://docs.mosaicml.com/en/stable/examples/custom_speedup_methods.html\n",
    "[ptl_tutorial]: https://docs.mosaicml.com/en/stable/examples/migrate_from_ptl.html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Come get involved with MosaicML!\n",
    "\n",
    "We'd love for you to get involved with MosaicML community in any of these ways:\n",
    "\n",
    "### [Star Composer on GitHub](https://github.com/mosaicml/composer)\n",
    "\n",
    "Stay up-to-date and help make others aware of our work by [starring Composer on GitHub](https://github.com/mosaicml/composer).\n",
    "\n",
    "### [Join the MosaicML Slack](https://join.slack.com/t/mosaicml-community/shared_invite/zt-w0tiddn9-WGTlRpfjcO9J5jyrMub1dg)\n",
    "\n",
    "Head on over to the [MosaicML slack](https://join.slack.com/t/mosaicml-community/shared_invite/zt-w0tiddn9-WGTlRpfjcO9J5jyrMub1dg) to join other ML efficiency enthusiasts. Come for the paper discussions, stay for the memes!\n",
    "\n",
    "### Contribute to Composer\n",
    "\n",
    "Is there a bug you noticed or a feature you'd like? File an [issue](https://github.com/mosaicml/composer/issues) or make a [pull request](https://github.com/mosaicml/composer/pulls)!"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
