{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/florescl/composer/blob/laura%2Ftpu-perf/TPU_Training_in_composer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pLQPoJ6Fn8wF"
   },
   "source": [
    "### TPU training in composer\n",
    "\n",
    "Composer provides beta support for single core training on TPUs. \n",
    "In this tutorial, we walk through how to train ReSnet-20 on CIFAR10 with minimal changes in composer. \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "__O91tR7Rh7O"
   },
   "source": [
    "As prerequisites, first install torch_xla and composer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wc711rY5RxFy"
   },
   "outputs": [],
   "source": [
    "!pip install cloud-tpu-client==0.10 torch==1.12.0 https://storage.googleapis.com/tpu-pytorch/wheels/colab/torch_xla-1.12-cp37-cp37m-linux_x86_64.whl\n",
    "%pip install mosaicml\n",
    "\n",
    "from composer import Trainer\n",
    "from composer import models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AqOqlKMNR3CR"
   },
   "source": [
    "Define the model, import xla and transfer the model to the xla device. This \n",
    "step needs to be performed before the optimizer is constructed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0J8AUm3HSAQH"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch_xla.core.xla_model as xm\n",
    "\n",
    "model = models.composer_resnet_cifar(model_name='resnet_20', num_classes=10)\n",
    "model = model.to(xm.xla_device())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DqjBwfb8SE0G"
   },
   "source": [
    "Now, let's load the CIFAR10 dataset, transforms and define the dataLoader, just like you would for your pytorch models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YwJEDZWxSJUX"
   },
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "\n",
    "data_directory = \"../data\"\n",
    "\n",
    "# Normalization constants\n",
    "mean = (0.507, 0.487, 0.441)\n",
    "std = (0.267, 0.256, 0.276)\n",
    "\n",
    "batch_size = 1024\n",
    "\n",
    "cifar10_transforms = transforms.Compose([transforms.ToTensor(), transforms.Normalize(mean, std)])\n",
    "\n",
    "train_dataset = datasets.CIFAR10(data_directory, train=True, download=True, transform=cifar10_transforms)\n",
    "test_dataset = datasets.CIFAR10(data_directory, train=False, download=True, transform=cifar10_transforms)\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pTRaag12SXU9"
   },
   "source": [
    "Similarly, we can define an optimizer in the same way as above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mZdVuMdQSNFv"
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(\n",
    "    model.parameters(),\n",
    "    lr=0.02,\n",
    "    momentum=0.9)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jnCqqWAhSafT"
   },
   "source": [
    "Now, we are ready to define the composer trainer by simply adding `device=\"tpu\"`. \n",
    "\n",
    "Now the model is ready to be trained on a single core TPU. Stay tuned for the next composer release for alpha support for multi core TPUs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TAZJT9LGSiyB"
   },
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    train_dataloader=train_dataloader,\n",
    "    device=\"tpu\",\n",
    "    eval_dataloader=test_dataloader,\n",
    "    optimizers=optimizer,\n",
    "    max_duration='20ep',\n",
    "    eval_interval=1,\n",
    ")\n",
    "\n",
    "trainer.fit()"
   ]
  }
 ],
 "metadata": {
  "gpuClass": "standard"
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
