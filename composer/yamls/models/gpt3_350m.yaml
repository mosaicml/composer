train_dataset:
  streaming_c4:
    version: 1
    remote: s3://mosaicml-internal-dataset-c4/mds/1/
    local: /tmp/mds-cache/mds-c4/
    split: train
    tokenizer_name: gpt2
    max_seq_len: 2048
    group_method: concat
    shuffle: true
    drop_last: true
val_dataset:
  streaming_c4:
    version: 1
    remote: s3://mosaicml-internal-dataset-c4/mds/1/
    local: /tmp/mds-cache/mds-c4/
    split: val
    tokenizer_name: gpt2
    max_seq_len: 2048
    group_method: concat
    shuffle: false
    drop_last: false
model:
  gpt2:
    use_pretrained: false
    tokenizer_name: gpt2
    model_config:
      activation_function: gelu_new
      architectures:
        - GPT2LMHeadModel
      attn_pdrop: 0.0
      bos_token_id: 50256
      embd_pdrop: 0.0
      eos_token_id: 50256
      initializer_range: 0.02
      layer_norm_epsilon: 1.0e-05
      model_type: gpt2
      n_embd: 1024
      n_head: 16
      n_inner: 4096
      n_layer: 24
      n_positions: 2048
      resid_pdrop: 0.0
      scale_attn_weights: true
      summary_activation: null
      summary_first_dropout: 0.0
      summary_proj_to_labels: true
      summary_type: cls_index
      summary_use_proj: true
      task_specific_params:
        text-generation:
          do_sample: true
          max_length: 50
      transformers_version: 4.16.2
      use_cache: true
      vocab_size: 50257
optimizers:
  decoupled_adamw:
    lr: 3.0e-4
    betas:
      - 0.9
      - 0.95
    eps: 1.0e-08
    weight_decay: 0.0
schedulers:
  - cosine_decay_with_warmup:
      t_warmup: 0.01dur
max_duration: 20000ba
train_batch_size: 256 # 0.5e6 tok ~= 256[bs] * 2048[msl]
grad_accum: 16 # 256[bs] / 8[devices] / 2[per_gpu_microbatch_size] = 16[ga], assuming 8xA100-40GB
eval_batch_size: 16 # 16[bs] / 8[devices] = 2[per_gpu_microbatch_size], assuming 8xA100-40GB
seed: 17
dataloader:
  pin_memory: true
  persistent_workers: true
  num_workers: 1
  timeout: 0
  prefetch_factor: 2
deepspeed_config:
  zero_optimization:
    stage: 0
algorithms:
  gradient_clipping:
    clipping_type: "norm"
    clipping_threshold: 1.0
eval_interval: 1000ba
