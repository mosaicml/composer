{
    "additionalProperties": false,
    "properties": {
        "drop_last": {
            "description": "Whether to drop the last samples for the last batch.",
            "type": "boolean"
        },
        "group_method": {
            "description": "How to group text samples into token samples. Either `truncate` or `concat`.",
            "oneOf": [
                {
                    "type": "string"
                },
                {
                    "type": "null"
                }
            ]
        },
        "max_seq_len": {
            "description": "The max sequence length of each token sample.",
            "oneOf": [
                {
                    "type": "integer"
                },
                {
                    "type": "null"
                }
            ]
        },
        "mlm": {
            "description": "Whether or not to use masked language modeling.",
            "type": "boolean"
        },
        "mlm_probability": {
            "description": "If `mlm==True`, the probability that tokens are masked.",
            "type": "number"
        },
        "num_samples": {
            "description": "The number of post-processed token samples, used to set epoch size of the IterableDataset.",
            "oneOf": [
                {
                    "type": "integer"
                },
                {
                    "type": "null"
                }
            ]
        },
        "seed": {
            "description": "If `shuffle=True`, what seed to use for shuffling operations.",
            "type": "integer"
        },
        "shuffle": {
            "description": "Whether to shuffle the samples in the dataset. Currently, shards are assigned and consumed with deterministic per-device shard order, but shuffling affects the order of samples via (per-device) shuffle buffers.",
            "type": "boolean"
        },
        "shuffle_buffer_size": {
            "description": "If `shuffle=True`, samples are read into a buffer of this size (per-device), and randomly sampled from there to produce shuffled samples.",
            "type": "integer"
        },
        "split": {
            "description": "What split of the dataset to use. Either `train` or `validation`.",
            "oneOf": [
                {
                    "type": "string"
                },
                {
                    "type": "null"
                }
            ]
        },
        "tokenizer_name": {
            "description": "The name of the HuggingFace tokenizer to preprocess text with.",
            "oneOf": [
                {
                    "type": "string"
                },
                {
                    "type": "null"
                }
            ]
        }
    },
    "referenced": false,
    "type": "object"
}
