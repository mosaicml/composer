pCloud = "colo-research-01"
gitUrl = null
gitBranch = null
gitCommit = null
pTimeout = '1800' // in seconds
pytorchDockerChanged = null
runWithChecks = null
expandDockerMatrix = null
prChangeset = null
builds = []
jenkinsJobBasePath = "scratch"

def cloneJenkinsfilesRepo() {
    // Clone the remote jenkins file in WORKSPACE_TMP
    dir ("$WORKSPACE_TMP") {
        checkout([  
            $class: 'GitSCM', 
            branches: [[name: 'main']], // TODO RJPP_BRANCH
            doGenerateSubmoduleConfigurations: false, 
            extensions: [[$class: 'RelativeTargetDirectory', relativeTargetDir: 'jenkinsfiles']], 
            submoduleCfg: [], 
            userRemoteConfigs: [[url: 'https://github.com/mosaicml/testing', credentialsId: "9cf9add1-2cdd-414b-8160-94bd4ac4a13d"]]  // TODO RJPP_SCM_URL
        ])
        return "$WORKSPACE_TMP/jenkinsfiles"
    }
}

def runPytest(Map args) {
    // Run pytest. Parameters
    // extraDeps (str, optional): The pip extra deps to install -- e.g. pip install mosaicml[$extraDeps]. (default: `all`)
    // pythonVersion (str, optional): The python version (should be 3.7, 3.8, or 3.9).
    //    Required if `pDockerImage` is left blank
    // gpu (bool, optional): Whether to run tests on a gpu (default: `False`)
    // pDockerImage (str, optional): Base docker image to use. Required if `pythonVersion` is left blank
    def extraDeps = args.extraDeps ?: 'all'
    def pythonVersion = args.pythonVersion
    def gpu = args.gpu ?: false
    def pDockerImage = args.pDockerImage
    def name = null 
    def title = null
    def summary = title
    if (!pDockerImage) {
        if (!pythonVersion) {
            error ("pDockerImage or pythonVersion must be specified")
        }
        def pytorchVersion = pythonVersion == "3.9" ? "1.10.0" : "1.9.1"
        name = "pytest/python${pythonVersion}-extraDeps_${extraDeps}-gpu_$gpu"
        tile = "Pytest - Python ${pythonVersion}, composer[${extraDeps}] (GPU $gpu)"
        pDockerImage = "mosaicml/pytorch:${pytorchVersion}_cpu-python${pythonVersion}-ubuntu20.04"
    }
    def pytestCliArgs = '--test_duration all'
    def nGpus = "0"
    def memLimit = "7Gi"
    def cpuLimit = "2"
    def markers = '""' // no markers. interpreted as a bash array

    if (gpu){
        nGpus = "2"
        cpuLimit = "16" // 8 cpu per gpu
        memLimit = "15Gi"  // 7.5Gb per gpu
        if (!pDockerImage) {
            def pytorchVersion = pythonVersion == "3.9" ? "1.10.0" : "1.9.1"
            def cudaVersion = pythonVersion == "3.9" ? "cu113" : "cu111"
            pDockerImage = "mosaicml/pytorch:${pytorchVersion}_${cudaVersion}-python${pythonVersion}-ubuntu20.04"
        }
        markers = '"gpu" "deepspeed"'  // interpreted as a bash array
    }

    def pytestCommand = """#!/bin/bash
set -euxo pipefail

EXTRA_DEPS=$extraDeps
MARKERS=($markers)

# Install dependencies
if [ -z "\$EXTRA_DEPS" ]; then
    pip install .
else
    pip install .[\$EXTRA_DEPS]
fi

# Disable WandB. Since WandB may not be installed, ignoring errors
set +e
python -m wandb disabled || true
set -e

# For each marker, run pytest
I=0
for marker in \${MARKERS[@]}; do
    if [ -n "\$marker" ]; then
        EXTRA="-m $marker"
    else
        EXTRA=""
    fi

    # Run the tests
    JUNIT_PREFIX=build/output/\$BUILD_NUMBER_\$I" ./scripts/test.sh --test_duration all -v \$EXTRA
    ((I=I+1))
done


# Combine the coverage reports
python -m coverage combine
python -m coverage xml -o build/output/\$BUILD_NUMBER.coverage.xml"""
    def closure = { ->
        builds << build(
            job: "${jenkinsJobBasePath}/command",
            parameters: [
                string(name: 'P_CLOUD', value: pCloud),
                string(name: 'P_GIT_REPO', value: gitUrl),
                string(name: 'P_GIT_COMMIT', value: gitCommit),
                string(name: 'P_DOCKER_IMAGE', value: pDockerImage),
                string(name: 'P_CPU_LIMIT', value: cpuLimit),
                string(name: 'P_MEM_LIMIT', value: memLimit),
                string(name: 'P_TIMEOUT', value: pTimeout),
                string(name: 'P_N_GPUS', value: nGpus),
                text(name: 'P_COMMAND', value: pytestCommand),
                string(name: 'P_ARTIFACTS_GLOB', value: "build/output/*.xml"),
                string(name: 'P_JUNIT_GLOB', value: "build/output/*.junit.xml"),
                string(name: 'P_COVERAGE_GLOB', value: "build/output/*.coverage.xml"),
            ]
        )
    }
    if (name && title && summary) {
        runWithChecks(
            name: name,
            title: title,
            summary: summary,
        ) {
            closure()
        }
    } else {
        closure()
    }
}

stage('Prepare') {
    node (pCloud) {
        // ITo get the commit url and hash, we must be on a real agent
        def loadedSCM = checkout scm

        gitUrl = loadedSCM.GIT_URL
        gitBranch = loadedSCM.GIT_BRANCH
        gitCommit = loadedSCM.GIT_COMMIT

        echo "gitUrl: $gitUrl"
        echo "gitBranch: $gitBranch"
        echo "gitCommit: $gitCommit"

        def jenkinsfileWorkspace = cloneJenkinsfilesRepo()

        runWithChecks = load "$jenkinsfileWorkspace/utils/runWithChecks.groovy"
        expandDockerMatrix = load "$jenkinsfileWorkspace/utils/expandDockerMatrix.groovy"
        prChangeset = load "$jenkinsfileWorkspace/utils/prChangeset.groovy"

        pytorchDockerChanged = prChangeset("docker/pytorch/")
    }
}

def dockerImagePostBuild(stagingImageTag) {
    if (gitBranch == "main") {
        // no need to run tests again
        return
    }
    runPytest(pDockerImage: stagingImageTag)
}

stage('Build') {
    def jobs = [:]
    if (pytorchDockerChanged) {
        jobs << expandDockerMatrix(
            P_CLOUD: pCloud,
            P_BUILD_MATRIX: './composer/pytorch_build_matrix.sh',
            P_BUILD_MATRIX_GIT_REPO: 'https://github.com/mosaicml/testing.git',  // TODO RJPP_SCM_URL
            P_BUILD_MATRIX_GIT_COMMIT: 'main', // TODO RJPP_BRANCH
            P_DOCKERFILE: 'Dockerfile',
            P_BUILD_CONTEXT: './docker/pytorch',
            P_GIT_REPO: gitUrl,
            P_GIT_COMMIT: gitCommit,
            P_CPU_LIMIT: '4',
            P_MEM_LIMIT: '15Gi',
            P_TIMEOUT: pTimeout,
            P_KANIKO_PUSH_FINAL: gitBranch == "dev" || gitBranch == "main", // only push if we're on the main or dev branch
        ) { stagingImage -> dockerImagePostBuild(stagingImage) }
    }
    if (gitBranch != "main" && gitBranch != "dev") {
        // if not on main or dev, run the pytest again.
        jobs << [
            'Lint': { -> 
                runWithChecks(
                    name: 'lint',
                    title: 'Lint',
                    summary: 'Static Analysis Checks',
                ) {
                    builds << build(
                        job: "${jenkinsJobBasePath}/command",
                        parameters: [
                            string(name: 'P_CLOUD', value: pCloud),
                            string(name: 'P_GIT_REPO', value: gitUrl),
                            string(name: 'P_GIT_COMMIT', value: gitCommit),
                            string(name: 'P_DOCKER_IMAGE', value: "mosaicml/pytorch:1.10.0_cpu-python3.9-ubuntu20.04"),
                            string(name: 'P_TIMEOUT', value: pTimeout),
                            string(name: 'P_CPU_LIMIT', value: "2"),
                            string(name: 'P_MEM_LIMIT', value: "7Gi"),
                            string(name: 'P_COMMAND', value: './scripts/lint.sh'),
                        ]
                    )
                }
            },
            'Python 3.7 - All': { -> runPytest(pythonVersion: "3.7", extraDeps: "all") },
            'Python 3.8 - All': { -> runPytest(pythonVersion: "3.8", extraDeps: "all") },
            'Python 3.9 - All': { -> runPytest(pythonVersion: "3.9", extraDeps: "all") },
            'Python 3.9 - Dev': { -> runPytest(pythonVersion: "3.9", extraDeps: "dev") },
            'Python 3.9 - All (GPU)': { -> runPytest(pythonVersion: "3.9", extraDeps: "all", gpu: True) },
        ]        
    }
    try {
        parallel(jobs)
    }
    finally {
        stage('Merge Artifacts') {
            node (pCloud) {
                checkout scm  // checking out the SCM so the coverage report can load the source
                builds.each { item -> 
                    copyArtifacts(
                        projectName: item.fullProjectName,
                        selector: specific("${item.number}"),
                        fingerprintArtifacts: true,
                        optional: true,
                    )
                }

                sh 'mkdir -p build/output/'

                archiveArtifacts(artifacts: "build/output/*.xml", fingerprint: true, allowEmptyArchive: true)
                junit(allowEmptyResults: true, testResults: "build/output/*.junit.xml")
                publishCoverage(
                    adapters: [cobertura(path: "build/output/*.coverage.xml", mergeToOneReport: true)],
                    calculateDiffForChangeRequests: true,
                    sourceFileResolver: [level: 'STORE_LAST_BUILD']
                )
            }
        }
    }
}
