/* groovylint-disable DuplicateMapLiteral, DuplicateStringLiteral, NestedBlockDepth */

// Cloud settings
pCloud = 'r1z3' // name of the jenkins cloud to use

// Git variables. These are populated during the "Prepare" stage
gitUrl = null
gitBranch = null
gitCommit = null
gitCommitHash = null
baseBranch = 'dev'  // the branch on which merge-commits should be pushed to dockerhub

// Docker build settings
pytorchDockerBuildMatrix = null // The pytorch docker build matrix
didDockerChange = false
dockerBuildCpuLimit = '4'
dockerBuildMemLimit = '50Gi'
dockerBuildTimeout = '7200'  // timeout for docker builds, in seconds. Builds from scratch can be slow.
// must use the kaniko debug image, as Jenkins needs shell access
// see https://github.com/GoogleContainerTools/kaniko#debug-image
kanikoDockerImage = 'gcr.io/kaniko-project/executor:v1.7.0-debug' // Docker image for kaniko docker builds
stagingDockerRepo = 'mosaicml/jenkins-staging'  // The repo where staging images are pushed
cacheRepo = 'mosaicml/docker-cache'  // The repo where docker image layers are cached

// Pytest settings
pytestTimeout = '1800' // timeout to run pytest, in seconds
pytestCpuTestCpuLimit = '4'
pytestCpuTestMemLimit = '20Gi' // memory limit for ram and ephemeral storage
pytestGpuTestNumGpus = 2
pytestGpuTestCpuLimit = '14'
pytestGpuTestMemLimit = '30Gi' // memory limit for ram and ephemeral storage
// Tags to run GPU image tests on when not building docker.
// If building docker, then GPU tests will be run across the entire matrix.
pytestGpuImageTagsToTest = [
    'mosaicml/pytorch:latest',
    'mosaicml/pytorch_vision:latest',
]
devInstallTestImage = 'mosaicml/pytorch:latest_cpu' // the image to use for the dev test installs

// Lint settings
lintImage = 'mosaicml/pytorch_vision:latest_cpu'
lintCpuLimit = '2'
lintMemLimit = '7Gi'
pLintTimeout = '1800' // timeout to run lint + doctests, in seconds

// Conda settings
dependenciesChanged = false // Whether meta.yaml or setup.py have changed, (if so, rebuild conda)
condaCpuLimit = '4'
condaMemLimit = '20Gi' // memory limit for ram and ephemeral storage
condaBuildDockerImage = 'continuumio/anaconda-pkg-build:2022.02.09-amd64'  // Docker image for conda builds
condaTimeout = '7200' // timeout for conda builds, in seconds

// Jenkins settings
numDaysOfBuildsToKeep = '7' // number of days to keep builds (so Jenkins doesn't crash)
jenkinsShellJobName = 'scratch/command2' // The jenkins job name used to spawn sub-jobs
gitCredentialsId = '9cf9add1-2cdd-414b-8160-94bd4ac4a13d' // Jenkins credential ID to use for git clones
wandbCredentialsId = 'e6fbcd33-e739-483f-a4a9-9b6815572c8b'
awsCredentialsId = 'd931e1a8-f356-42f4-bc4d-bc8582c3bf9e'
sshCredentialsId = 'f71fda19-c867-4e7b-b6e8-3894e8288076'

// Artifact setting
buildOutputFolder = 'build/output' // Folder where build artifacts are stored
artifactsGlob = "$buildOutputFolder/**" // Files matching this glob will be archived by Jenkins
junitGlob = "$buildOutputFolder/*.junit.xml" // Files matching this glob will be presented Junit test reports
coverageGlob = "$buildOutputFolder/*.coverage.xml" // Files matching this glob will be presented Junit coverage reports

// Spawned builds
builds = [] // List of spawned sub-jobs


properties(
    [
        buildDiscarder(
            logRotator(daysToKeepStr: numDaysOfBuildsToKeep, artifactDaysToKeepStr: numDaysOfBuildsToKeep)
        ),
    ]
)

@NonCPS
Boolean isPathModified(...prefixes) {
    // returns whether any file in the PR (or commit if it's a merge commit)
    // starts with any specified prefix
    def changedFiles = []

    // Adapted from
    // https://stackoverflow.com/questions/50437626/how-to-get-list-of-all-modified-files-in-pipeline-jenkins
    currentBuild.changeSets.each { entries ->
        entries.each { entry ->
            entry.affectedFiles.each { file ->
                changedFiles << file.path
            }
        }
    }
    if (env.CHANGE_ID) {
        // it's a PR, so look at all files in the PR rather than just
        // the most recent commit
        changedFiles = pullRequest.files.collect { file -> file.filename }
    }
    for (changedFile in changedFiles) {
        for (prefix in prefixes) {
            if (changedFile.startsWith(prefix)) {
                return true
            }
        }
    }
    return false
}

String generateStagingImageTag() {
    // Generates a staging image tag
    String stagingTag = UUID.randomUUID()
    return "${stagingDockerRepo}:${stagingTag}"
}

def getKanikoCommand(buildArgs) {
    // Constructs a kaniko command from the buildArgs
    def cliArgsList = []
    def tags = []
    buildArgs.each { key, val ->
        if (key == 'TAGS') {
            val.each { tag ->
                tags << tag
            }
            return
        }
        if (key == 'TARGET') {
            cliArgsList << "--target '$val'"
            return
        }
        cliArgsList << "--build-arg '$key=$val'"
    }
    String cliArgs = cliArgsList.join(' ')
    String kanikoCommand = '/kaniko/executor --cache=true --dockerfile Dockerfile --context ./docker --cleanup'
    kanikoCommand += " --cache-repo=${cacheRepo} ${cliArgs}"
    for (tag in tags) {
        kanikoCommand += " --destination $tag"
    }

    if (cliArgs.contains(cacheRepo)) {
        error("The kaniko args should not ever attempt to push images to the cache repo, ${cacheRepo}")
    }

    return kanikoCommand
}


void trackBuild(Map buildArgs) {
    // 1. Run a build() command, but manually echo a link to the spawned job, since it may not show up
    //    in blue ocean. See https://issues.jenkins.io/browse/JENKINS-60995.
    // 2. Add the build to the `builds` variable
    buildArgs['propagate'] = false
    def builtJob = build(buildArgs)
    builds << builtJob
    if (builtJob.result == 'SUCCESS') {
        echo "Job ${builtJob.fullDisplayName} was successful. See ${builtJob.absoluteUrl} for details."
    }
    else {
        error "Job ${builtJob.fullDisplayName} failed. See ${builtJob.absoluteUrl} for details."
    }
}

void runLint(String pDockerImage) {
    trackBuild(
        job: jenkinsShellJobName,
        parameters: [
            string(name: 'P_CLOUD', value: pCloud),
            string(name: 'P_GIT_REPO', value: gitUrl),
            string(name: 'P_GIT_COMMIT', value: gitCommit),
            string(name: 'P_EPHEMERAL_STORAGE_LIMIT', value: lintMemLimit),
            booleanParam(name: 'P_USE_TMP_RAMDISK', value: true),
            string(name: 'P_DOCKER_IMAGE', value: pDockerImage),
            string(name: 'P_TIMEOUT', value: pLintTimeout),
            string(name: 'P_CPU_LIMIT', value: lintCpuLimit),
            string(name: 'P_MEM_LIMIT', value: lintMemLimit), // must include the ephemeral storage limit
            string(name: 'P_COMMAND', value: './.ci/lint_doctests.sh'),
            string(name: 'P_ARTIFACTS_GLOB', value: artifactsGlob),
            string(name: 'P_JUNIT_GLOB', value: junitGlob),
            string(name: 'P_COVERAGE_GLOB', value: coverageGlob),
        ]
    )
}

void scheduleJob(jobs, String image, buildArgs, originalTags) {
    // jobs: The list of jobs. Modified in-place.
    // buildArgs: The build args matrix
    // originalTags: The original tags

    String markers = 'not daily'
    Boolean isLintImage = false
    Boolean isVisionImage = false
    Boolean isDevTestInstallImage = false
    Boolean isGpu = false
    String tag = originalTags[0]
    buildArgs.each { key, val ->
        if (key == 'CUDA_VERSION') {
            if (val != '') {
                isGpu = true
            }
        }
        if (key == 'TARGET' && val == 'vision_stage') {
            isVisionImage = true
        }
    }
    originalTags.each { tagName ->
        isLintImage = isLintImage || tagName == lintImage
        isDevTestInstallImage = isDevTestInstallImage || tagName == devInstallTestImage
    }
    String extraDeps = 'all'

    if (isVisionImage) {
        markers = "$markers and vision"
    }
    else {
        markers = "$markers and not vision"
    }

    if (isGpu) {
        markers = "$markers and gpu"
    }
    else {
        markers = "$markers and not gpu"
    }

    jobs << [
        "Pytest - ${tag}" : { -> runPytest(image, markers, extraDeps, isGpu) }
    ]
    if (isDevTestInstallImage) {
        jobs << [
            'Pytest - extraDeps=dev': { -> runPytest(image, markers, 'dev', isGpu) },
        ]
    }
    if (isLintImage) {
        // and run lint and a dev install on this image
        jobs << [
            'Lint': { -> runLint(image) },
        ]
    }
}

void runPytest(String pDockerImage, String markers, String extraDeps, Boolean isGpu) {
    // pDockerImage (str): Base docker image to use.
    // extraDeps (str): The pip extra deps to install -- e.g. "pip install "mosaicml[$extraDeps]".
    // markers (str): Pyetst markers
    // isGpu (Boolean): Whether the test requires gpus
    String nGpus = '0'
    String cpuLimit = pytestCpuTestCpuLimit
    String memLimit = pytestCpuTestMemLimit

    if (isGpu) {
        nGpus = pytestGpuTestNumGpus
        cpuLimit = pytestGpuTestCpuLimit
        memLimit = pytestGpuTestMemLimit
    }

    trackBuild(
        job: jenkinsShellJobName,
        parameters: [
            string(name: 'P_CLOUD', value: pCloud),
            string(name: 'P_GIT_REPO', value: gitUrl),
            string(name: 'P_GIT_COMMIT', value: gitCommit),
            string(name: 'P_DOCKER_IMAGE', value: pDockerImage),
            string(name: 'P_CPU_LIMIT', value: cpuLimit),
            string(name: 'P_MEM_LIMIT', value: memLimit),
            string(name: 'P_TIMEOUT', value: pytestTimeout),
            string(name: 'P_N_GPUS', value: nGpus),
            string(name: 'P_EPHEMERAL_STORAGE_LIMIT', value: memLimit),
            booleanParam(name: 'P_USE_TMP_RAMDISK', value: true),
            text(name: 'P_COMMAND', value: "./.ci/test.sh '$extraDeps' '$markers'"),
            string(
                name: 'P_JENKINS_USERNAME_PASSWORD_CREDENTIALS',
                value: "IGNORED_WANDB_USERNAME,WANDB_API_KEY=$wandbCredentialsId",
            ),
            string(
                name: 'P_JENKINS_AWS_CREDENTIALS',
                value: awsCredentialsId,
            ),
            string(
                name: 'P_JENKINS_SSH_CREDENTIALS',
                value: sshCredentialsId,
            ),
            string(name: 'P_ARTIFACTS_GLOB', value: artifactsGlob),
            string(name: 'P_JUNIT_GLOB', value: junitGlob),
            string(name: 'P_COVERAGE_GLOB', value: coverageGlob),
        ]
    )
}

stage('Prepare') {
    node(pCloud) {
        // Automatically cancel old builds only on PR builds
        // From https://stackoverflow.com/questions/40760716/jenkins-abort-running-build-if-new-one-is-started
        if (env.CHANGE_ID) {  // if it is a PR build
            int buildNumber = env.BUILD_NUMBER as int
            if (buildNumber > 1) {
                milestone(buildNumber - 1)
            }
            milestone(buildNumber)
        }

        def loadedSCM = checkout scm

        gitUrl = loadedSCM.GIT_URL
        gitBranch = loadedSCM.GIT_BRANCH
        gitCommit = loadedSCM.GIT_COMMIT
        gitCommitHash = loadedSCM.GIT_COMMIT

        if (env.CHANGE_ID) {
            // Use the origin/pr/PR_NUMBER/merge to support commits in external repos
            gitCommit = "origin/pr/${pullRequest.number}/merge"
        }

        echo "gitUrl: $gitUrl"
        echo "gitBranch: $gitBranch"
        echo "gitCommit: $gitCommit"

        didDockerChange = isPathModified('docker/')
        pytorchDockerBuildMatrix = readYaml(file:  './docker/build_matrix.yaml')

        // Keep track of whether dependencies changed, in which case a conda build should be tested
        dependenciesChanged = isPathModified('setup.py') || isPathModified('meta.yaml')
    }
}

stage('Build') {
    def jobs = [:]
    Boolean isMergeCommit = true
    if (env.CHANGE_ID) {
        isMergeCommit = false
    }

    pytorchDockerBuildMatrix.each { buildArgs ->
        Boolean isComposerImage = buildArgs['TARGET'] == 'composer_stage'
        Boolean shouldPushToDestinations = isMergeCommit && gitBranch == baseBranch
        Boolean shouldBuildImage = didDockerChange  // Always build the image if the ./docker folder changed

        def originalTags = buildArgs['TAGS']

        if (!shouldPushToDestinations) {
            buildArgs['TAGS'] = []
        }

        if (isComposerImage && buildArgs['COMPOSER_INSTALL_COMMAND'] == 'mosaicml[all]GIT_COMMIT') {
            // If this is a composer image and it is the 'GIT_COMMIT' entry in the matrix
            // then build and publish the image on the staging repo
            if (!shouldPushToDestinations) {
                // Skip composer images except on merge commits on the dev branch -- it's slow!
                return
            }
            String stagingTagName = "mosaicml/composer_staging:${gitCommitHash[0..6]}"
            if (!buildArgs['CUDA_VERSION']) {
                stagingTagName += '_cpu'
            }
            buildArgs['COMPOSER_INSTALL_COMMAND'] = "mosaicml[all] @ git+https://github.com/mosaicml/composer.git@${gitCommitHash}"
            buildArgs['TAGS'] << stagingTagName
            shouldBuildImage = true  // always build the image if it's a composer image
        }

        if (shouldBuildImage) {
            String stagingImageTag = generateStagingImageTag()
            buildArgs['TAGS'] << stagingImageTag
            String kanikoCommand = getKanikoCommand(buildArgs)
            jobs << [ "${buildArgs}": { ->
                trackBuild(
                    job: jenkinsShellJobName,
                    parameters: [
                        string(name: 'P_CLOUD', value: pCloud),
                        string(name: 'P_GIT_REPO', value: gitUrl),
                        string(name: 'P_GIT_COMMIT', value: gitCommit),
                        string(name: 'P_DOCKER_IMAGE', value: kanikoDockerImage),
                        string(name: 'P_EPHEMERAL_STORAGE_LIMIT', value: dockerBuildMemLimit),
                        text(name: 'P_COMMAND', value: kanikoCommand),
                        string(name: 'P_TIMEOUT', value: dockerBuildTimeout),
                        string(name: 'POD_TIMEOUT', value: dockerBuildTimeout),
                        string(name: 'P_CPU_LIMIT', value: dockerBuildCpuLimit),
                        string(name: 'P_MEM_LIMIT', value: dockerBuildMemLimit),
                        booleanParam(name: 'P_MOUNT_KANIKO_CREDENTIALS', value: true),
                    ]
                )
                if (!isComposerImage) {
                    // Only run tests on the 'mosaicml/pytorch' or 'mosaicml/pytorch_vision' images,
                    // not 'mosaicml/composer'
                    def subJobs = [:]
                    scheduleJob(subJobs, stagingImageTag, buildArgs, originalTags)
                    if (!isMergeCommit) {
                        // Fail fast only on PR builds
                        subJobs.failFast = true
                    }
                    parallel(subJobs)
                }
            }]
        }
        else if (!isComposerImage) {
            // If not rebuilding the docker image, and it's not a composer image, then run CPU tests acorss all images,
            // and run GPU tests only on the "latest" image
            // Only run tests on the 'mosaicml/pytorch' or 'mosaicml/pytorch_vision' images -- not 'mosaicml/composer'
            Boolean isCpuImage = buildArgs['CUDA_VERSION'] == ''
            Boolean shouldRunGpuTests = false

            originalTags.each { tag ->
                if (pytestGpuImageTagsToTest.contains(tag)) {
                    shouldRunGpuTests = true
                }
            }

            if (isCpuImage || shouldRunGpuTests) {
                String existingImageTag = originalTags[0]
                scheduleJob(jobs, existingImageTag, buildArgs, originalTags)
            }
        }
    }

    if (dependenciesChanged) {
        // Regardless of whether the docker image changed, rebuild the conda package
        // if the dependencies changed

        // Conda is temporarily being disabled due to issues it's having with dependency
        // solving for mpi. It will be re-enabled once the conda issue https://github.com/conda/conda/issues/11442
        // is closed by this PR https://github.com/conda/conda/pull/11612.
        // jobs << [
        //     'Conda': { ->
        //         trackBuild(
        //             job: jenkinsShellJobName,
        //             parameters: [
        //                 string(name: 'P_CLOUD', value: pCloud),
        //                 string(name: 'P_GIT_REPO', value: gitUrl),
        //                 string(name: 'P_GIT_COMMIT', value: gitCommit),
        //                 string(name: 'P_EPHEMERAL_STORAGE_LIMIT', value: condaMemLimit),
        //                 string(name: 'P_DOCKER_IMAGE', value: condaBuildDockerImage),
        //                 string(name: 'P_TIMEOUT', value: condaTimeout), // Conda builds take longer
        //                 string(name: 'POD_TIMEOUT', value: condaTimeout),
        //                 string(name: 'P_CPU_LIMIT', value: condaCpuLimit),
        //                 string(name: 'P_MEM_LIMIT', value: condaMemLimit),  // must include the ephemeral storage limit
        //                 string(name: 'P_COMMAND', value: './.ci/build_conda.sh')
        //             ]
        //         )
        //     }
        // ]
    }
    if (!isMergeCommit) {
        // Fail fast only on PR builds
        jobs.failFast = true
    }
    try {
        parallel(jobs)
    }
    finally {
        stage('Merge Artifacts') {
            node(pCloud) {
                checkout scm  // checking out the SCM so the coverage report can load the source
                builds.each { item ->
                    copyArtifacts(
                        projectName: item.fullProjectName,
                        selector: specific("${item.number}"),
                        fingerprintArtifacts: true,
                        optional: true,
                    )
                }

                sh "mkdir -p $buildOutputFolder"

                archiveArtifacts(artifacts: artifactsGlob, fingerprint: true, allowEmptyArchive: true)
                junit(allowEmptyResults: true, testResults: junitGlob, checksName: 'Tests', keepLongStdio: true)
                publishCoverage(
                    adapters: [cobertura(path: coverageGlob, mergeToOneReport: true)],
                    calculateDiffForChangeRequests: true,
                    sourceFileResolver: [level: 'STORE_LAST_BUILD']
                )
            }
        }
    }
}
