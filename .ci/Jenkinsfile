pCloud = "colo-research-01"
gitUrl = null
gitBranch = null
gitCommit = null
pytorchDockerChanged = null
runWithChecks = null
expandDockerMatrix = null
prChangeset = null
builds = []

def cloneJenkinsfilesRepo() {
    // Clone the remote jenkins file in WORKSPACE_TMP
    dir ("$WORKSPACE_TMP") {
        checkout([  
            $class: 'GitSCM', 
            branches: [[name: 'main']], // TODO RJPP_BRANCH
            doGenerateSubmoduleConfigurations: false, 
            extensions: [[$class: 'RelativeTargetDirectory', relativeTargetDir: 'jenkinsfiles']], 
            submoduleCfg: [], 
            userRemoteConfigs: [[url: 'https://github.com/mosaicml/testing', credentialsId: "9cf9add1-2cdd-414b-8160-94bd4ac4a13d"]]  // TODO RJPP_SCM_URL
        ])
        return "$WORKSPACE_TMP/jenkinsfiles"
    }
}

def runPytest(pythonVersion, extraDeps, gpu = false, marker = "") {
    def name = "pytest/python${pythonVersion}-extraDeps_${extraDeps}-$marker"
    def title = "Pytest - Python ${pythonVersion}, composer[${extraDeps}] ($marker)"
    def summary = title
    def pytorchVersion = pythonVersion == "3.9" ? "1.10.0" : "1.9.1"
    def pDockerImage = "mosaicml/pytorch:${pytorchVersion}_cpu-python${pythonVersion}-ubuntu20.04"
    def pytestCliArgs = '--test_duration all'
    def nGpus = "0"
    def memLimit = "7Gi"
    def cpuLimit = "2"

    if (gpu){
        nGpus = "2"
        cpuLimit = "16" // 8 cpu per gpu
        memLimit = "15Gi"  // 7.5Gb per gpu
        def cudaVersion = pythonVersion == "3.9" ? "cu113" : "cu111"
        pDockerImage = "mosaicml/pytorch:${pytorchVersion}_${cudaVersion}-python${pythonVersion}-ubuntu20.04"
    }
    if (marker) {
        pytestCliArgs = "$pytestCliArgs -m $marker"
    }
    runWithChecks(
        name: name,
        title: title,
        summary: summary,
    ) {
        echo "$title"
        builds << build(
            job: 'scratch/pytest',
            parameters: [
                string(name: 'P_CLOUD', value: pCloud),
                string(name: 'P_GIT_REPO', value: gitUrl),
                string(name: 'P_GIT_COMMIT', value: gitCommit),
                string(name: 'P_DOCKER_IMAGE', value: pDockerImage),
                string(name: 'P_CPU_LIMIT', value: cpuLimit),
                string(name: 'P_MEM_LIMIT', value: memLimit),
                string(name: 'P_TIMEOUT', value: '1800'),
                string(name: 'PIP_EXTRA_DEPS', value: extraDeps),
                string(name: 'PYTEST_COMMAND', value: './scripts/test.sh'),
                string(name: 'PYTEST_CLI_ARGS', value: pytestCliArgs),
                string(name: 'P_N_GPUS', value: nGpus),
            ]
        )
    }
}

stage('Prepare') {
    node (pCloud) {
        // In order to print the env and get the commit url and hash, we must be on a real agent
        sh 'printenv'

        def loadedSCM = checkout scm

        sh 'printenv'

        gitUrl = loadedSCM.GIT_URL
        gitBranch = loadedSCM.GIT_BRANCH
        gitCommit = loadedSCM.GIT_COMMIT

        echo "gitUrl: $gitUrl"
        echo "gitBranch: $gitBranch"
        echo "gitCommit: $gitCommit"

        def jenkinsfileWorkspace = cloneJenkinsfilesRepo()

        runWithChecks = load "$jenkinsfileWorkspace/utils/runWithChecks.groovy"
        expandDockerMatrix = load "$jenkinsfileWorkspace/utils/expandDockerMatrix.groovy"
        prChangeset = load "$jenkinsfileWorkspace/utils/prChangeset.groovy"

        pytorchDockerChanged = prChangeset("docker/pytorch/")
    }
}

def dockerImagePostBuild(stagingImageTag) {
    if (gitBranch == "main") {
        // no need to run tests again
        return
    }
    parallel([
        "$stagingImageTag - all": { ->
            build(
                job: 'scratch/pytest',
                parameters: [
                    string(name: 'P_CLOUD', value: pCloud),
                    string(name: 'P_GIT_REPO', value: gitUrl),
                    string(name: 'P_GIT_COMMIT', value: gitCommit),
                    string(name: 'P_DOCKER_IMAGE', value: stagingImageTag),
                    string(name: 'P_CPU_LIMIT', value: "2"),
                    string(name: 'P_MEM_LIMIT', value: "7Gi"),
                    string(name: 'P_TIMEOUT', value: '1800'),
                    string(name: 'PIP_EXTRA_DEPS', value: 'all'),
                    string(name: 'PYTEST_COMMAND', value: './scripts/test.sh'),
                    string(name: 'PYTEST_CLI_ARGS', value: '--test_duration all'),
                ]
            )
        }
    ])
}

stage('Build') {
    def jobs = [:]
    if (pytorchDockerChanged) {
        jobs << expandDockerMatrix(
            P_CLOUD: pCloud,
            P_BUILD_MATRIX: './composer/pytorch_build_matrix.sh',
            P_BUILD_MATRIX_GIT_REPO: 'https://github.com/mosaicml/testing.git',  // TODO RJPP_SCM_URL
            P_BUILD_MATRIX_GIT_COMMIT: 'main', // TODO RJPP_BRANCH
            P_DOCKERFILE: 'Dockerfile',
            P_BUILD_CONTEXT: './docker/pytorch',
            P_GIT_REPO: gitUrl,
            P_GIT_COMMIT: gitCommit,
            P_CPU_LIMIT: '4',
            P_MEM_LIMIT: '15Gi',
            P_TIMEOUT: '3600',
            P_KANIKO_PUSH_FINAL: gitBranch == "main", // only push if we're on the main branch
        ) { stagingImage -> dockerImagePostBuild(stagingImage) }
    }
    if (gitBranch != "main" && gitBranch != "dev") {
        // if not on main or dev, run the pytest again.
        jobs << [
            'Lint': { -> 
                runWithChecks(
                    name: 'lint',
                    title: 'Lint',
                    summary: 'Static Analysis Checks',
                ) {
                    builds << build(
                        job: 'scratch/lint',
                        parameters: [
                            string(name: 'P_CLOUD', value: pCloud),
                            string(name: 'P_GIT_REPO', value: gitUrl),
                            string(name: 'P_GIT_COMMIT', value: gitCommit),
                            string(name: 'P_DOCKER_IMAGE', value: "mosaicml/pytorch:1.10.0_cpu-python3.9-ubuntu20.04"),
                            string(name: 'P_TIMEOUT', value: '1800'),
                            string(name: 'P_CPU_LIMIT', value: "2"),
                            string(name: 'P_MEM_LIMIT', value: "7Gi"),
                            string(name: 'PIP_EXTRA_DEPS', value: 'all'),
                        ]
                    )
                }
            },
            'Python 3.7 - All': { -> runPytest("3.7", "all") },
            'Python 3.8 - All': { -> runPytest("3.8", "all") },
            'Python 3.9 - All': { -> runPytest("3.9", "all") },
            'Python 3.9 - Dev': { -> runPytest("3.9", "dev") },
            'Python 3.9 - All (GPU)': { -> runPytest("3.9", "all", true, "gpu") },
            'Python 3.9 - All (GPU-Deepspeed)': { -> runPytest("3.9", "all", true, "deepspeed") },
        ]        
    }
    try {
        parallel(jobs)
    }
    finally {
        stage('Merge Artifcats') {
            node (pCloud) {
                checkout scm  // checking out the SCM so the coverage report can load the source
                builds.each { item -> 
                    copyArtifacts(
                        projectName: item.fullProjectName,
                        selector: specific("${item.number}"),
                        fingerprintArtifacts: true,
                        optional: true,
                    )
                }

                sh 'ls -al'

                sh 'mkdir -p build/output/'

                sh 'ls -al build/output/'
                archiveArtifacts(artifacts: "build/output/*.xml", fingerprint: true, allowEmptyArchive: true)
                junit(allowEmptyResults: true, testResults: "build/output/*.junit.xml")
                publishCoverage(
                    adapters: [cobertura(path: "build/output/*.coverage.xml", mergeToOneReport: true)],
                    calculateDiffForChangeRequests: true,
                    sourceFileResolver: [level: 'STORE_LAST_BUILD']
                )
            }
        }
    }
}
