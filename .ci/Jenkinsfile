groovyLoadLabel = "aws-next-01"
gitUrl = null
gitBranch = null
gitCommit = null
pytorchChanged = null  // TODO. Determine if the PR changes the docker.
runWithChecks = null
expandDockerMatrix = null
prChangeset = null
builds = []

def cloneJenkinsfilesRepo() {
    // Clone the remote jenkins file in WORKSPACE_TMP
    dir ("$WORKSPACE_TMP") {
        checkout([  
            $class: 'GitSCM', 
            branches: [[name: 'main']], // TODO RJPP_BRANCH
            doGenerateSubmoduleConfigurations: false, 
            extensions: [[$class: 'RelativeTargetDirectory', relativeTargetDir: 'jenkinsfiles']], 
            submoduleCfg: [], 
            userRemoteConfigs: [[url: 'https://github.com/mosaicml/testing', credentialsId: "9cf9add1-2cdd-414b-8160-94bd4ac4a13d"]]  // TODO RJPP_SCM_URL
        ])
        return "$WORKSPACE_TMP/jenkinsfiles"
    }
}

def runPytest(pythonVersion, extraDeps, nGpus = 0) {
    runWithChecks(
        name: "pytest/python${pythonVersion}-extraDeps_${extraDeps}-nGpus_${nGpus}",
        title: "Pytest - Python ${pythonVersion}, composer[${extraDeps}], ${nGpus} GPUs",
        summary: "Pytest - Python ${pythonVersion}, composer[${extraDeps}], ${nGpus} GPUs",
    ) {
        echo "Pytest - Python ${pythonVersion}, composer[${extraDeps}], ${nGpus} GPUs"
        builds << build(
            job: 'scratch/pytest',
            parameters: [
                string(name: 'P_CLOUD', value: nGpus == 0 ? "aws-next-01" : "p2.xlarge"),
                string(name: 'P_GIT_REPO', value: gitUrl),
                string(name: 'P_GIT_COMMIT', value: gitCommit),
                string(name: 'P_DOCKER_IMAGE', value: "ravimosaicml/pytorch:1.10.0_cpu-python${pythonVersion}-ubuntu20.04"), // TODO: change ravi to mosaicml/pytorch
                string(name: 'P_TIMEOUT', value: '1800'),
                string(name: 'PIP_EXTRA_DEPS', value: extraDeps),
                string(name: 'PYTEST_CLI_ARGS', value: '--test_duration all'),
                string(name: 'P_NODE_SELECTOR', value: nGpus == 0 ? "c5.large" : "p2.xlarge"),
            ]
        )
    }
}

stage('Prepare') {
    node (groovyLoadLabel) {
        // In order to print the env and get the commit url and hash, we must be on a real agent
        sh 'printenv'

        def loadedSCM = checkout scm

        sh 'printenv'

        gitUrl = loadedSCM.GIT_URL
        gitBranch = loadedSCM.GIT_BRANCH
        gitCommit = loadedSCM.GIT_COMMIT

        echo "gitUrl: $gitUrl"
        echo "gitBranch: $gitBranch"
        echo "gitCommit: $gitCommit"

        def jenkinsfileWorkspace = cloneJenkinsfilesRepo()

        runWithChecks = load "$jenkinsfileWorkspace/utils/runWithChecks.groovy"
        expandDockerMatrix = load "$jenkinsfileWorkspace/utils/expandDockerMatrix.groovy"
        prChangeset = load "$jenkinsfileWorkspace/utils/prChangeset.groovy"

        pytorchChanged = prChangeset("docker/pytorch/")
    }
}

def dockerImagePostBuild(stagingImageTag) {
    if (gitBranch == "main") {
        // no need to run tests again
        return
    }
    parallel([
        "$stagingImageTag - dev": { ->
            build(
                job: 'scratch/pytest',
                parameters: [
                    string(name: 'P_CLOUD', value: groovyLoadLabel),
                    string(name: 'P_GIT_REPO', value: gitUrl),
                    string(name: 'P_GIT_COMMIT', value: gitCommit),
                    string(name: 'P_DOCKER_IMAGE', value: stagingImageTag),
                    string(name: 'P_TIMEOUT', value: '30'),
                    string(name: 'PIP_EXTRA_DEPS', value: 'dev'),
                    string(name: 'PYTEST_CLI_ARGS', value: '--test_duration all'),
                ]
            )
        },
        "$stagingImageTag - all": { ->
            build(
                job: 'scratch/pytest',
                parameters: [
                    string(name: 'P_CLOUD', value: groovyLoadLabel),
                    string(name: 'P_GIT_REPO', value: gitUrl),
                    string(name: 'P_GIT_COMMIT', value: gitCommit),
                    string(name: 'P_DOCKER_IMAGE', value: stagingImageTag),
                    string(name: 'P_TIMEOUT', value: '30'),
                    string(name: 'PIP_EXTRA_DEPS', value: 'all'),
                    string(name: 'PYTEST_CLI_ARGS', value: '--test_duration all'),
                ]
            )
        }
    ])
}

stage('Build') {
    def jobs = [:]
    pytorchChanged = false // TODO remove. Adding this in so kube doesn't failover
    if (pytorchChanged) {
        jobs << expandDockerMatrix(
            P_CLOUD: groovyLoadLabel,
            P_BUILD_MATRIX: './composer/pytorch_build_matrix.sh',
            P_BUILD_MATRIX_GIT_REPO: 'https://github.com/mosaicml/testing.git',  // TODO RJPP_SCM_URL
            P_BUILD_MATRIX_GIT_COMMIT: 'main', // TODO RJPP_BRANCH
            P_DOCKERFILE: 'Dockerfile',
            P_BUILD_CONTEXT: './docker/pytorch',
            P_GIT_REPO: gitUrl,
            P_GIT_COMMIT: gitCommit,
            P_TIMEOUT: '30',
            P_KANIKO_PUSH_FINAL: gitBranch == "main", // only push if we're on the main branch
        ) { stagingImage -> dockerImagePostBuild(stagingImage) }
    }
    if (gitBranch != "main") {
        // if not on main, run the pytest again.
        jobs << [
            'Lint': { -> 
                runWithChecks(
                    name: 'lint',
                    title: 'Lint',
                    summary: 'Static Analysis Checks',
                ) {
                    builds << build(
                        job: 'scratch/lint',
                        parameters: [
                            string(name: 'P_CLOUD', value: groovyLoadLabel),
                            string(name: 'P_GIT_REPO', value: gitUrl),
                            string(name: 'P_GIT_COMMIT', value: gitCommit),
                            string(name: 'P_DOCKER_IMAGE', value: "ravimosaicml/pytorch:1.10.0_cpu-python3.9-ubuntu20.04"), // TODO: change ravimosaicml/pytorch to mosaicml/pytorch
                            string(name: 'P_TIMEOUT', value: '1800'),
                            string(name: 'PIP_EXTRA_DEPS', value: 'all'),
                        ]
                    )
                }
            },
            'Python 3.7 - All 0 GPUs': { -> runPytest("3.7", "all", 0) },
            'Python 3.8 - All 0 GPUs': { -> runPytest("3.8", "all", 0) },
            'Python 3.9 - All 0 GPUs': { -> runPytest("3.9", "all", 0) },
            'Python 3.9 - Dev 0 GPUs': { -> runPytest("3.9", "dev", 0) },
            // 'Python 3.9 - All 1 GPU': { -> runPytest("3.9", "all", 1) },
            // 'Python 3.9 - All 2 GPUs': { -> runPytest("3.9", "all", 2) },
        ]        
    }
    try {
        parallel(jobs)
    }
    finally {
        stage('Merge Artifcats') {
            node ("aws-next-01") {
                builds.each { item -> 
                    copyArtifacts(
                        projectName: item.fullProjectName,
                        selector: specific("${item.number}"),
                        fingerprintArtifacts: true,
                    )
                }

                sh 'ls -al'

                sh 'mkdir -p build/output/'

                sh 'ls -al build/output/'

                checkout scm  // checking out the SCM so the coverage report can load the source

                archiveArtifacts(artifacts: "build/output/*.xml", fingerprint: true, allowEmptyArchive: true)
                junit(allowEmptyResults: true, testResults: "build/output/*.junit.xml")
                publishCoverage(
                    adapters: [cobertura(path: "build/output/*.coverage.xml", mergeToOneReport: true)],
                    calculateDiffForChangeRequests: true,
                    sourceFileResolver: [level: 'STORE_LAST_BUILD']
                )
            }
        }
    }
}
