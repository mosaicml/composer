pCloud = "colo-research-01"
gitUrl = null
gitBranch = null
gitCommit = null
pTimeout = '1800' // in seconds
pytorchDockerChanged = null
runWithChecks = null
expandDockerMatrix = null
prChangeset = null
builds = []
jenkinsJobBasePath = "scratch"

def cloneJenkinsfilesRepo() {
    // Clone the remote jenkins file in WORKSPACE_TMP
    dir ("$WORKSPACE_TMP") {
        checkout([
            $class: 'GitSCM',
            branches: [[name: 'main']], // TODO RJPP_BRANCH
            doGenerateSubmoduleConfigurations: false,
            extensions: [[$class: 'RelativeTargetDirectory', relativeTargetDir: 'jenkinsfiles']],
            submoduleCfg: [],
            userRemoteConfigs: [[url: 'https://github.com/mosaicml/testing', credentialsId: "9cf9add1-2cdd-414b-8160-94bd4ac4a13d"]]  // TODO RJPP_SCM_URL
        ])
        return "$WORKSPACE_TMP/jenkinsfiles"
    }
}

def runPytest(Map args) {
    // Run pytest. Parameters
    // extraDeps (str, optional): The pip extra deps to install -- e.g. pip install mosaicml[$extraDeps]. (default: `all`)
    // pythonVersion (str, optional): The python version (should be 3.7, 3.8, or 3.9).
    //    Required if `pDockerImage` is left blank
    // gpu (bool, optional): Whether to run tests on a gpu (default: `false`)
    // pDockerImage (str, optional): Base docker image to use. Required if `pythonVersion` is left blank
    def extraDeps = args.extraDeps ?: 'all'
    def pythonVersion = args.pythonVersion
    def gpu = args.gpu ?: false
    def pDockerImage = args.pDockerImage
    def nGpus = "0"
    def memLimit = "7Gi"
    def cpuLimit = "2"
    def markers = '""' // no markers. interpreted as a bash array

    if (gpu){
        nGpus = "2"
        cpuLimit = "16" // 8 cpu per gpu
        memLimit = "15Gi"  // 7.5Gb per gpu
        markers = '"gpu" "deepspeed"'  // interpreted as a bash array
    }

    def name = null
    def title = null
    if (!pDockerImage) {
        if (!pythonVersion) {
            error ("pDockerImage or pythonVersion must be specified")
        }
        def pytorchVersion = pythonVersion == "3.9" ? "1.10.0" : "1.9.1"
        name = "pytest/python${pythonVersion}-extraDeps_${extraDeps}-gpu_$gpu"
        title = "Pytest - Python ${pythonVersion}, composer[${extraDeps}] (GPU $gpu)"
        def cudaVersion = "cpu"
        if (gpu) {
            cudaVersion = pythonVersion == "3.9" ? "cu113" : "cu111"

        }
        pDockerImage = "mosaicml/pytorch:${pytorchVersion}_${cudaVersion}-python${pythonVersion}-ubuntu20.04"
    }
    def summary = title

    def pytestCommand = """#!/usr/bin/env bash
set -euxo pipefail

EXTRA_DEPS=$extraDeps
MARKERS=($markers)

# Install dependencies
if [ -z "\${EXTRA_DEPS}" ]; then
    pip install .
else
    pip install .[\${EXTRA_DEPS}]
fi

# Disable WandB. Since WandB may not be installed, ignoring errors
set +e
python -m wandb disabled || true
set -e

# For each marker, run pytest
I=0
if [ -n "\${MARKERS}"]; then
    JUNIT_PREFIX=build/output/\${BUILD_NUMBER}_\${I} ./scripts/test.sh --duration all -v
    ((I=I+1))
else
    for marker in \${MARKERS[@]}; do
        # Run the tests
        JUNIT_PREFIX=build/output/\${BUILD_NUMBER}_\${I} ./scripts/test.sh --duration all -v -m \$marker
        ((I=I+1))
    done
fi

# Combine the coverage reports
python -m coverage combine
python -m coverage xml -o build/output/\${BUILD_NUMBER}.coverage.xml"""

    def closure = { ->
        builds << build(
            job: "${jenkinsJobBasePath}/command",
            parameters: [
                string(name: 'P_CLOUD', value: pCloud),
                string(name: 'P_GIT_REPO', value: gitUrl),
                string(name: 'P_GIT_COMMIT', value: gitCommit),
                string(name: 'P_DOCKER_IMAGE', value: pDockerImage),
                string(name: 'P_CPU_LIMIT', value: cpuLimit),
                string(name: 'P_MEM_LIMIT', value: memLimit),
                string(name: 'P_TIMEOUT', value: pTimeout),
                string(name: 'P_N_GPUS', value: nGpus),
                text(name: 'P_COMMAND', value: pytestCommand),
                string(name: 'P_ARTIFACTS_GLOB', value: "build/output/*.xml"),
                string(name: 'P_JUNIT_GLOB', value: "build/output/*.junit.xml"),
                string(name: 'P_COVERAGE_GLOB', value: "build/output/*.coverage.xml"),
            ]
        )
    }
    if (name != null && title != null && summary != null) {
        runWithChecks(
            name: name,
            title: title,
            summary: summary,
        ) {
            closure()
        }
    } else {
        closure()
    }
}

stage('Prepare') {
    node (pCloud) {
        def loadedSCM = checkout scm

        gitUrl = loadedSCM.GIT_URL
        gitBranch = loadedSCM.GIT_BRANCH
        gitCommit = loadedSCM.GIT_COMMIT

        if (env.CHANGE_ID) {
            // Use the origin/pr/PR_NUMBER/head to support commits in external repos
            gitCommit = "origin/pr/${pullRequest.number}/head"
        }

        echo "gitUrl: $gitUrl"
        echo "gitBranch: $gitBranch"
        echo "gitCommit: $gitCommit"

        def jenkinsfileWorkspace = cloneJenkinsfilesRepo()

        runWithChecks = load "$jenkinsfileWorkspace/utils/runWithChecks.groovy"
        expandDockerMatrix = load "$jenkinsfileWorkspace/utils/expandDockerMatrix.groovy"
        prChangeset = load "$jenkinsfileWorkspace/utils/prChangeset.groovy"

        pytorchDockerChanged = prChangeset("docker/pytorch/")
    }
}

def dockerImagePostBuild(stagingImageTag) {
    if (gitBranch == "main") {
        // no need to run tests again
        return
    }
    runPytest(pDockerImage: stagingImageTag)
}

stage('Build') {
    def jobs = [:]
    if (pytorchDockerChanged) {
        jobs << expandDockerMatrix(
            P_CLOUD: pCloud,
            P_BUILD_MATRIX: './composer/pytorch_build_matrix.sh',
            P_BUILD_MATRIX_GIT_REPO: 'https://github.com/mosaicml/testing.git',  // TODO RJPP_SCM_URL
            P_BUILD_MATRIX_GIT_COMMIT: 'main', // TODO RJPP_BRANCH
            P_DOCKERFILE: 'Dockerfile',
            P_BUILD_CONTEXT: './docker/pytorch',
            P_GIT_REPO: gitUrl,
            P_GIT_COMMIT: gitCommit,
            P_CPU_LIMIT: '4',
            P_MEM_LIMIT: '15Gi',
            P_TIMEOUT: pTimeout,
            P_KANIKO_PUSH_FINAL: gitBranch == "dev" || gitBranch == "main", // only push if we're on the main or dev branch
        ) { stagingImage -> dockerImagePostBuild(stagingImage) }
    }
    if (gitBranch != "main" && gitBranch != "dev") {
        // if not on main or dev, run the pytest again.
        jobs << [
            'Lint': { ->
                runWithChecks(
                    name: 'lint',
                    title: 'Lint',
                    summary: 'Static Analysis Checks',
                ) {
                    builds << build(
                        job: "${jenkinsJobBasePath}/command",
                        parameters: [
                            string(name: 'P_CLOUD', value: pCloud),
                            string(name: 'P_GIT_REPO', value: gitUrl),
                            string(name: 'P_GIT_COMMIT', value: gitCommit),
                            string(name: 'P_DOCKER_IMAGE', value: "mosaicml/pytorch:1.10.0_cpu-python3.9-ubuntu20.04"),
                            string(name: 'P_TIMEOUT', value: pTimeout),
                            string(name: 'P_CPU_LIMIT', value: "2"),
                            string(name: 'P_MEM_LIMIT', value: "7Gi"),
                            string(name: 'P_COMMAND', value: 'make lint'),
                        ]
                    )
                }
            },
            'Python 3.7 - All': { -> runPytest(pythonVersion: "3.7") },
            'Python 3.8 - All': { -> runPytest(pythonVersion: "3.8") },
            'Python 3.9 - All': { -> runPytest(pythonVersion: "3.9") },
            'Python 3.9 - Dev': { -> runPytest(pythonVersion: "3.9", extraDeps: "dev") },
            'Python 3.9 - All (GPU)': { -> runPytest(pythonVersion: "3.9", gpu: true) },
        ]
    }
    jobs.failFast = true
    try {
        parallel(jobs)
    }
    finally {
        stage('Merge Artifacts') {
            node (pCloud) {
                checkout scm  // checking out the SCM so the coverage report can load the source
                builds.each { item ->
                    copyArtifacts(
                        projectName: item.fullProjectName,
                        selector: specific("${item.number}"),
                        fingerprintArtifacts: true,
                        optional: true,
                    )
                }

                sh 'mkdir -p build/output/'

                archiveArtifacts(artifacts: "build/output/*.xml", fingerprint: true, allowEmptyArchive: true)
                junit(allowEmptyResults: true, testResults: "build/output/*.junit.xml")
                publishCoverage(
                    adapters: [cobertura(path: "build/output/*.coverage.xml", mergeToOneReport: true)],
                    calculateDiffForChangeRequests: true,
                    sourceFileResolver: [level: 'STORE_LAST_BUILD']
                )
            }
        }
    }
}
